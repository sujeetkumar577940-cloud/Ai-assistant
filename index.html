<!DOCTYPE html>
<html lang="hi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aaradhiya AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <style>
        * {
            box-sizing: border-box;
        }
        html, body {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            background-color: #0c0c1e;
            font-family: 'Orbitron', sans-serif;
            color: #fff;
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #animationContainer {
            position: relative;
            width: 100%;
            max-width: 800px;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #videoSizer {
            position: relative;
            width: 100%;
            aspect-ratio: 1/1;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        .assistant-video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            object-fit: contain;
            opacity: 0;
            transition: opacity 0.5s ease;
            pointer-events: none;
        }
        .assistant-video.is-active {
            opacity: 1;
        }
        #userVideo {
            position: absolute;
            top: 20px;
            right: 20px;
            width: 180px;
            height: 135px;
            border-radius: 12px;
            border: 2px solid #28a745;
            box-shadow: 0 0 15px rgba(40, 167, 69, 0.5);
            transform: scaleX(-1);
            background: #000;
            display: none;
            z-index: 10;
        }
        .controls {
            position: absolute;
            bottom: 40px;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            gap: 20px;
            z-index: 20;
        }
        button {
            width: 70px;
            height: 70px;
            border-radius: 50%;
            border: none;
            font-size: 28px;
            cursor: pointer;
            transition: transform 0.2s, box-shadow 0.2s;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
        }
        #mainButton {
            background: #28a745;
            box-shadow: 0 0 20px rgba(40, 167, 69, 0.4);
        }
        #videoCallButton {
            background: #007bff;
            box-shadow: 0 0 20px rgba(0, 123, 255, 0.4);
        }
        button:hover {
            transform: scale(1.1);
        }
        #dev-attribution {
            position: absolute;
            bottom: 10px;
            font-size: 10px;
            letter-spacing: 1px;
            opacity: 0.6;
            z-index: 5;
        }
        #dev-attribution a {
            color: #00d4ff;
            text-decoration: none;
        }
        @media (max-width: 768px) {
            #animationContainer {
                height: 100vh;
                max-width: none;
            }
            #videoSizer {
                height: 100%;
                width: auto;
                aspect-ratio: auto;
            }
            #userVideo {
                width: 120px;
                height: 90px;
                top: 10px;
                right: 10px;
            }
        }
    </style>
</head>
<body>

    <div id="animationContainer">
        <div id="videoSizer">
            <video id="silentVideo" class="assistant-video is-active" src="assets/silent.mp4#t=1" muted loop playsinline></video>
            <video id="thinkVideo" class="assistant-video" src="assets/think.mp4" playsinline></video>
            <video id="speakVideo" class="assistant-video" src="assets/speak.mp4" muted loop playsinline></video>
        </div>
    </div>

    <video id="userVideo" autoplay playsinline></video>

    <div class="controls">
        <button id="mainButton">üìû</button>
        <button id="videoCallButton">üìπ</button>
    </div>

    <div id="dev-attribution"></div>

    <script>
        const HF_TOKEN = "HUGGING_FACE_TOKEN";
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.lang = 'hi-IN';
        recognition.continuous = false;
        recognition.interimResults = false;

        let visionModel = null;
        let isVideoActive = false;
        let hasSpokenGreeting = false;

        const silentVid = document.getElementById('silentVideo');
        const thinkVid = document.getElementById('thinkVideo');
        const speakVid = document.getElementById('speakVideo');
        const userVideo = document.getElementById('userVideo');
        const mainBtn = document.getElementById('mainButton');
        const videoBtn = document.getElementById('videoCallButton');

        window.onload = () => {
            setAnimationState('silent');
            initAttribution();
        };

        function setAnimationState(state) {
            [silentVid, thinkVid, speakVid].forEach(v => {
                v.classList.remove('is-active');
                v.pause();
            });
            if (state === 'silent') {
                silentVid.classList.add('is-active');
                silentVid.play();
            } else if (state === 'think') {
                thinkVid.classList.add('is-active');
                thinkVid.currentTime = 0;
                thinkVid.play();
            } else if (state === 'speak') {
                speakVid.classList.add('is-active');
                speakVid.play();
            }
        }

        function speak(text) {
            return new Promise((resolve) => {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.lang = 'hi-IN';
                utterance.onstart = () => setAnimationState('speak');
                utterance.onend = () => {
                    setAnimationState('silent');
                    resolve();
                };
                window.speechSynthesis.speak(utterance);
            });
        }

        async function queryDeepSeekTextOnly(prompt) {
            try {
                const response = await fetch("https://api-inference.huggingface.co/models/deepseek-ai/DeepSeek-V3", {
                    method: "POST",
                    headers: {
                        "Authorization": `Bearer ${HF_TOKEN}`,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({
                        inputs: `System: You are Aaradhiya, a highly advanced futuristic AI assistant. Respond concisely in Hindi. Prompt: ${prompt}`,
                    })
                });
                const result = await response.json();
                return result[0]?.generated_text || "‡§Æ‡§æ‡§´‡§º ‡§ï‡•Ä‡§ú‡§ø‡§Ø‡•á, ‡§Æ‡•à‡§Ç ‡§Ö‡§≠‡•Ä ‡§á‡§∏‡§ï‡§æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡•Ä‡•§";
            } catch (e) {
                return "‡§ï‡•ç‡§∑‡§Æ‡§æ ‡§ï‡§∞‡•á‡§Ç, ‡§∏‡§∞‡•ç‡§µ‡§∞ ‡§∏‡•á ‡§∏‡§Ç‡§™‡§∞‡•ç‡§ï ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§™‡§æ ‡§∞‡§π‡§æ ‡§π‡•à‡•§";
            }
        }

        async function queryWithLocalVision(prompt) {
            let context = "";
            if (visionModel && isVideoActive) {
                const predictions = await visionModel.detect(userVideo);
                if (predictions.length > 0) {
                    const items = predictions.map(p => p.class).join(', ');
                    context = ` [User is showing: ${items}]`;
                }
            }
            return queryDeepSeekTextOnly(prompt + context);
        }

        async function handleCommand(command) {
            setAnimationState('think');
            let response = "";
            const lowerCmd = command.toLowerCase();

            if (lowerCmd.includes('‡§®‡§Æ‡§∏‡•ç‡§§‡•á')) {
                response = "‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∏‡§∞, ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡•á‡§µ‡§æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å?";
            } else if (lowerCmd.includes('‡§ü‡§æ‡§á‡§Æ') || lowerCmd.includes('‡§∏‡§Æ‡§Ø')) {
                response = `‡§Ö‡§≠‡•Ä ‡§∏‡§Æ‡§Ø ‡§π‡•à ${new Date().toLocaleTimeString('hi-IN')}`;
            } else {
                response = await queryWithLocalVision(command);
            }
            await speak(response);
        }

        mainBtn.onclick = async () => {
            if (!hasSpokenGreeting) {
                await speak("‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§π‡•à‡•§ ‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∏‡§∞, ‡§Æ‡•à‡§Ç ‡§Ü‡§∞‡§æ‡§ß‡•ç‡§Ø‡§æ ‡§π‡•Ç‡§Å‡•§");
                hasSpokenGreeting = true;
            }
            recognition.start();
        };

        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            handleCommand(transcript);
        };

        async function toggleVideoCall() {
            if (!isVideoActive) {
                try {
                    await speak("‡§µ‡§ø‡•õ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§≤‡•ã‡§° ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ç‡§∑‡§æ ‡§ï‡§∞‡•á‡§Ç‡•§");
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    userVideo.srcObject = stream;
                    userVideo.style.display = "block";
                    isVideoActive = true;
                    if (!visionModel) {
                        visionModel = await cocoSsd.load();
                    }
                    await speak("‡§µ‡§ø‡•õ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§Ö‡§¨ ‡§∏‡§ï‡•ç‡§∞‡§ø‡§Ø ‡§π‡•à‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•ã ‡§¶‡•á‡§ñ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Å‡•§");
                } catch (err) {
                    await speak("‡§ï‡•à‡§Æ‡§∞‡§æ ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡§∞‡§®‡•á ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ ‡§Ü ‡§∞‡§π‡•Ä ‡§π‡•à‡•§");
                }
            } else {
                const tracks = userVideo.srcObject.getTracks();
                tracks.forEach(track => track.stop());
                userVideo.style.display = "none";
                isVideoActive = false;
                await speak("‡§µ‡§ø‡•õ‡§® ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§¨‡§Ç‡§¶ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§");
            }
        }

        videoBtn.onclick = toggleVideoCall;

        function initAttribution() {
            const eId = atob('ZGV2LWF0dHJpYnV0aW9u');
            const eTxt = atob('RGV2ZWxvcGVkIEJ5IEphdmFHb2F0IFlvdXR1YmUgQ2hhbm5lbA==');
            const eUrl = atob('aHR0cHM6Ly93d3cueW91dHViZS5jb20vQGphdmFnb2F0cw==');
            const container = document.getElementById(eId);
            if (container) {
                const link = document.createElement('a');
                link.href = eUrl;
                link.innerText = eTxt;
                link.target = "_blank";
                container.appendChild(link);
            }
            checkAttribution();
            setInterval(checkAttribution, 1500);
        }

        function checkAttribution() {
            const eId = atob('ZGV2LWF0dHJpYnV0aW9u');
            const eTxt = atob('RGV2ZWxvcGVkIEJ5IEphdmFHb2F0IFlvdXR1YmUgQ2hhbm5lbA==');
            const eUrl = atob('aHR0cHM6Ly93d3cueW91dHViZS5jb20vQGphdmFnb2F0cw==');
            const el = document.getElementById(eId);
            if (!el) {
                document.body.innerHTML = '<h1 style="color: red; text-align: center; margin-top: 20%;">Tampering is not allowed</h1>';
                return;
            }
            const link = el.querySelector('a');
            if (!link || link.getAttribute('href') !== eUrl || link.innerText !== eTxt) {
                document.body.innerHTML = '<h1 style="color: red; text-align: center; margin-top: 20%;">Tampering is not allowed</h1>';
            }
        }
    </script>
</body>
</html>